{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6650bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from scipy.io import wavfile as wav\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import progressbar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8cce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('metadata/Screamsound.csv')\n",
    "valid_data = data[['slice_file_name', 'fold' ,'classID', 'class']][ data['end']-data['start'] > 0 ]\n",
    "valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aced43ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_14492\\2032816338.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for row in tqdm_notebook(valid_data.itertuples()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27ed5d2be6342d69b66a22c737e146b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold2/100652-3-0-0.wav\n",
      "1\n",
      "fold2/100652-3-0-1.wav\n",
      "1\n",
      "fold2/100652-3-0-2.wav\n",
      "1\n",
      "fold2/100652-3-0-3.wav\n",
      "1\n",
      "fold2/101415-3-0-2.wav\n",
      "1\n",
      "fold2/101415-3-0-3.wav\n",
      "1\n",
      "fold2/101415-3-0-8.wav\n",
      "1\n",
      "fold1/yisell_sound_2007_11_9_1_31_156634.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_25_315033.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_25_593398.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_26_248752.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_26_444257.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_27_063699.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_27_324809.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_27_543156.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_29_067921.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_29_33722.wav\n",
      "0\n",
      "fold1/yisell_sound_2007_12_18_15_30_231364.wav\n",
      "0\n",
      "fold1/yisell_sound_2014080511023849341_66366.wav\n",
      "0\n",
      "fold1/yisell_sound_2014080512323863957_66366.wav\n",
      "0\n",
      "fold1/yisell_sound_2014081313495332740_66366.wav\n",
      "0\n",
      "fold1/yisell_sound_2014081314482020626_66366.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n",
      "fold3/pk1e5-yogtt.wav\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "D=[]\n",
    "        \n",
    "for row in tqdm_notebook(valid_data.itertuples()): \n",
    "    print(row.path)\n",
    "    print(row.classID)\n",
    "    y1, sr1 = librosa.load(\"audio/\" + row.path, duration=2.97)  \n",
    "    ps = librosa.feature.melspectrogram(y=y1, sr=sr1)\n",
    "    #print(ps)\n",
    "    #print(ps.shape)\n",
    "    if ps.shape != (128, 128): \n",
    "            continue\n",
    "    D.append( (ps, row.classID) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588e84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hickle as hkl \n",
    "#data = D\n",
    "\n",
    "## Dump data to file\n",
    "#hkl.dump(data, 'new_data_file.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4456d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from file\n",
    "#D = hkl.load('new_data_file.hkl')\n",
    "#print(type(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72588a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils import np_utils\n",
    "#dataset = D\n",
    "#random.shuffle(dataset)\n",
    "\n",
    "#train = dataset[:15]\n",
    "#test = dataset[15:]\n",
    "#print('dataset:', len(dataset))\n",
    "#print('train:', len(train))\n",
    "#print('test:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d092c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split([i[0] for i in D],\n",
    "                                                   [i[1] for i in D],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=0)\n",
    "\n",
    "#X_train, y_train = zip(*train)\n",
    "#X_test, y_test = zip(*test)\n",
    "\n",
    "X_train = np.array([x.reshape( (128, 128, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 128, 1) ) for x in X_test])\n",
    "\n",
    "y_train = np.array(keras.utils.np_utils.to_categorical(y_train, 10))\n",
    "y_test = np.array(keras.utils.np_utils.to_categorical(y_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ed9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(128, 128, 1)\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b223268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.9917 - val_accuracy: 0.5000\n",
      "Epoch 2/24\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.9917 - val_accuracy: 0.5000\n",
      "Epoch 3/24\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3.4968e-07 - accuracy: 1.0000 - val_loss: 5.2562 - val_accuracy: 0.5000\n",
      "Epoch 4/24\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4711 - val_accuracy: 0.5000\n",
      "Epoch 5/24\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6418 - val_accuracy: 0.5000\n",
      "Epoch 6/24\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.8517 - val_accuracy: 0.2500\n",
      "Epoch 7/24\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0886 - val_accuracy: 0.2500\n",
      "Epoch 8/24\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.3505 - val_accuracy: 0.2500\n",
      "Epoch 9/24\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.6222 - val_accuracy: 0.2500\n",
      "Epoch 10/24\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.5895e-08 - accuracy: 1.0000 - val_loss: 6.9113 - val_accuracy: 0.2500\n",
      "Epoch 11/24\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5110 - accuracy: 0.9333 - val_loss: 7.8479 - val_accuracy: 0.5000\n",
      "Epoch 12/24\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 4.0133e-06 - accuracy: 1.0000 - val_loss: 9.7475 - val_accuracy: 0.5000\n",
      "Epoch 13/24\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.4924 - val_accuracy: 0.5000\n",
      "Epoch 14/24\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 13.3061 - val_accuracy: 0.5000\n",
      "Epoch 15/24\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 5.5631e-08 - accuracy: 1.0000 - val_loss: 15.1382 - val_accuracy: 0.5000\n",
      "Epoch 16/24\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.7602 - accuracy: 0.9333 - val_loss: 14.4124 - val_accuracy: 0.5000\n",
      "Epoch 17/24\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 8.7420e-08 - accuracy: 1.0000 - val_loss: 13.9370 - val_accuracy: 0.5000\n",
      "Epoch 18/24\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 13.5059 - val_accuracy: 0.5000\n",
      "Epoch 19/24\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 13.1541 - val_accuracy: 0.5000\n",
      "Epoch 20/24\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 12.9203 - val_accuracy: 0.5000\n",
      "Epoch 21/24\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 5.5631e-08 - accuracy: 1.0000 - val_loss: 12.6847 - val_accuracy: 0.5000\n",
      "Epoch 22/24\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 7.9473e-08 - accuracy: 1.0000 - val_loss: 12.5563 - val_accuracy: 0.5000\n",
      "Epoch 23/24\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 12.5073 - val_accuracy: 0.5000\n",
      "Epoch 24/24\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 12.4587 - val_accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 12.4587 - accuracy: 0.5000\n",
      "Test loss: 12.458671569824219\n",
      "Test accuracy: 0.5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (32, 128, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n    \n    Negative dimension size caused by subtracting 5 from 1 for '{{node sequential/conv2d/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/ExpandDims, sequential/conv2d/Conv2D/ReadVariableOp)' with input shapes: [32,128,1,1], [5,5,1,24].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(32, 128, 1, 1), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(predict)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n    \n    Negative dimension size caused by subtracting 5 from 1 for '{{node sequential/conv2d/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/ExpandDims, sequential/conv2d/Conv2D/ReadVariableOp)' with input shapes: [32,128,1,1], [5,5,1,24].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(32, 128, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    epochs=24,\n",
    "    batch_size=128,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "    x=X_test,\n",
    "    y=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "predict = model.predict(X_test[0])\n",
    "print(predict)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    epochs=24,\n",
    "    batch_size=128,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "    x=X_test,\n",
    "    y=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ScreamDemo1.h5') \n",
    "print('Model exported and finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d7a4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
